{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ad0edc9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 03 Lecture: Neural Network Architectures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279e22ec",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the lecture we will survey the following types of neural networks:\n",
    "\n",
    "1. Convolutional Neural Networks\n",
    "2. Graph Neural Networks\n",
    "3. Recurrent Neural Networks\n",
    "4. Attention and Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc99354",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19912f2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img alt=\"image_with_pixels\" src=\"https://github.com/ADicksonLab/ml4md-jb/raw/main/Week-03/image_pixels.png\" width=\"500px\"/>\n",
    "\n",
    "Convolutional networks were initialy motivated by image processing tasks (2D data x 3 colors)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55374896",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img alt=\"convolutional_network\" src=\"https://github.com/ADicksonLab/ml4md-jb/raw/main/Week-03/convolution.png\" width=\"600px\"/>\n",
    "\n",
    "Convolutional networks operate on multi-dimensional data by applying filters that are scanned over the data by focusing on **data proximity**.  \n",
    "\n",
    "The filters are small matrices that capture **local** features. The small size of the filters also has practical advantages (less memory, easier training).\n",
    "\n",
    "Convolutional layers  **encode** multi-dimensional data. Fully connected linear layers may be used to 'read out' desired classifiers or values.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339b702a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img alt=\"convolution_operation\" src=\"https://github.com/ADicksonLab/ml4md-jb/raw/main/Week-03/convolution_operation.png\" width=\"800px\"/>\n",
    "\n",
    "The convolution operation involves the dot product between the weight matrix calculated by sliding over the input data with the results accumulated across all input layers. \n",
    "\n",
    "Input data may be **padded** with zeros. The **stride** determines how much the weight matrix is advanced at every step. The number of weight matrices determines the **depth of the output layer**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5904bc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img alt=\"pooling operation\" src=\"https://github.com/ADicksonLab/ml4md-jb/raw/main/Week-03/pooling.png\" width=\"500px\"/>\n",
    "\n",
    "Pooling may be used to combine data and reduce the dimensionality. \n",
    "\n",
    "In most recent networks larger strides are used instead of pooling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f2c37f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img alt=\"alex_net\" src=\"https://miro.medium.com/max/1400/1*wzflNwJw9QkjWWvTosXhNw.png\" width=\"800px\"/>\n",
    "\n",
    "AlexNet is a convolutional network that was very successful 'early on' (i.e. 2012) with image classification in the [ImageNet Large Scale Visual Recognition Challenge](http://www.image-net.org/challenges/LSVRC/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c3fcda",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img alt=\"alex_net\" src=\"https://open-instruction.com/loading/2021/05/q.png\" width=\"800px\"/>\n",
    "\n",
    "ResNet architectures are more advanced convolutional network with additional 'shortcut' connections to transfer information between more distant layers. \n",
    "\n",
    "The main advantage of this architecture is to facilitate the training of very deep networks where vanishing gradients are a common problem. In ResNet models, skipped layers can be excluded initially and added back later to 'fine-tune' a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d4a4fa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img alt=\"image_classification\" src=\"https://cs.stanford.edu/people/karpathy/cnnembed/cnn_embed_full_1k.jpg\" width=\"500px\"/>\n",
    "\n",
    "Recent networks are even more complicated and can outperform humans in correctly classifiyng objects seen in images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b382df0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img alt=\"image_classification\" src=\"https://kpwulab.files.wordpress.com/2021/04/p5_j18_2d_classes_for_iteration_20.png\" width=\"600px\"/>\n",
    "\n",
    "Convolutional networks can be used for the classification of images in many areas of science, e.g. cryo-electron microscopy images. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30bed5d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img alt=\"distance_matrix\" src=\"https://nanohub.org/app/site/resources/2010/10/09924/5002/1ubq.jpg\" width=\"600px\"/>\n",
    "\n",
    "Convolutional networks are also well-suited for processing data such as **distance matrices**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d029b7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img alt=\"xray_density_volumet\" src=\"https://www.ruppweb.org/Xray/tutorial/Maps/bundle_map_bonds.GIF\" width=\"500px\"/>\n",
    "\n",
    "**density grid volumes** can be handled via 3D convolutional networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee95f178",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img alt=\"multiple_sequence_alignment\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/7/79/RPLP0_90_ClustalW_aln.gif/1150px-RPLP0_90_ClustalW_aln.gif\" width=\"700px\"/>\n",
    "\n",
    "**multiple sequence alignments** are also suitable for convolutional networks after generating a suitable representation of the alignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e21396",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Graph Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c03e35",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img alt=\"graph_neural_network\" src=\"https://github.com/ADicksonLab/ml4md-jb/raw/main/Week-03/gnn.png\" width=\"700px\"/>\n",
    "\n",
    "Graph neural networks are designed to capture data that is described by graphs that consist of **nodes** connected by **edges**. \n",
    "\n",
    "Transformations between layers maintain connections and edge properties. Nodes are transformed via convolutions over neighboring nodes. The functions **f** and **g** may be represented as fully connected neural networks with trainable weights.  \n",
    "\n",
    "For more information check [here](https://distill.pub/2021/gnn-intro/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6629b75",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img alt=\"molecule\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Demeton_-Molecule-3D-balls-by-AHRLS.png/800px-Demeton_-Molecule-3D-balls-by-AHRLS.png\" width=\"500px\"/>\n",
    "\n",
    "Graph neural networks are especially relevant for representing molecules:\n",
    "\n",
    "* Nodes: **atoms** with properties: chemical type, radius, charge, mass, coordinates\n",
    "* Edges: **bonds** with properties: single/double, covalent, hydrogen-bonding, non-bonded contact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236618c0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "When applied to 3D objects, GNNs should maintain **equivariance** with respect to translations and rotations. Otherwise, the network model has to learn that translation/rotation does not change objects, training is difficult, and model output is more likely to be non-physical. \n",
    "\n",
    "For an input layer $x$ that is transformed to a new layer $y = \\phi(x)$ this requires:\n",
    "\n",
    "* translation equivariance: $ y + T = \\phi(x + T) $\n",
    "* rotational equivariance: $ Ry = \\phi(Rx) $ \n",
    "\n",
    "<img alt=\"equivariance\" src=\"https://github.com/ADicksonLab/ml4md-jb/raw/main/Week-03/equivariance.png\" width=\"400 px\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090bdd66",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### E(n) Equivariant Graph Neural Networks\n",
    "Satorras, Hoogeboom, Welling: [arXiv: 2102.09844 (2021)] (https://arxiv.org/abs/2102.09844)\n",
    "\n",
    "<img alt=\"egnn\" src=\"https://github.com/ADicksonLab/ml4md-jb/raw/main/Week-03/egnn.png\" />\n",
    "\n",
    "Strategies for achieving equivariant transformations typically involve relative distances and radial or spherical harmonic functions.\n",
    "\n",
    "Other relevant papers on [tensor field networks](https://arxiv.org/abs/1802.08219) and [SE(3) Transformers](https://arxiv.org/abs/2006.10503)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79e06a0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46427fa4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img alt=\"natural_language_orocessing\" src=\"https://www.cesarsway.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-08-at-1.29.12-PM.png\" width=\"300px\"/>\n",
    "\n",
    "<img alt=\"natural_language_orocessing\" src=\"https://github.com/ADicksonLab/ml4md-jb/raw/main/Week-03/squirrels.png\" width=\"500px\"/>\n",
    "\n",
    "\n",
    "\n",
    "Recurrent neural networks focus on capturing **sequential processes** and were initialy motivated by natural language processing tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f0bef9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img alt=\"recurrent neural network all-to-all\" src=\"https://github.com/ADicksonLab/ml4md-jb/raw/main/Week-03/rnn_all_to_all.png\" width=\"500px\"/>\n",
    "\n",
    "Recurrent neural networks involve a hidden state **h** that is propagated iteratively using the **same weight matrix**, e.g. with the following non-linear function:\n",
    "\n",
    "$$\n",
    "h_i = \\tanh(w_{hh} h_{i-1} + w_{xh} x_i)\n",
    "$$\n",
    "\n",
    "Another recurring weight matrix is used to calculate output values:\n",
    "\n",
    "$$\n",
    "y_i = w_{hy} h_i\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f659e13",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img alt=\"recurrent neural network one-to-one\" src=\"https://github.com/ADicksonLab/ml4md-jb/raw/main/Week-03/rnn_one_to_one.png\" width=\"500px\"/>\n",
    "\n",
    "In model variations there may be input only at the beginning and at the end.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d818ebf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img alt=\"recurrent neural network one-to-all\" src=\"https://github.com/ADicksonLab/ml4md-jb/raw/main/Week-03/rnn_one_to_all.png\" width=\"500px\"/>\n",
    "\n",
    "Or continuous output may be generated iteratively from initial input. \n",
    "\n",
    "This looks a lot like a conformational sampling algorithm!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b40a698",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img alt=\"long_short_term_memory\" src=\"https://github.com/ADicksonLab/ml4md-jb/raw/main/Week-03/lstm.png\" width=\"600px\"/>\n",
    "\n",
    "A traditional RNN is difficult to train because input at early times affects output much later (vanishing gradients). The LSTM (long short term memory) model provides more control how information is retained over many interations and makes the training of RNNs easier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8c1fe6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Solving Newton's Equations of Motion with Large Timesteps using Recurrent Neural Networks based Operators\n",
    "Kadupitiya, Fox, Jadhao: [arXiv: 2004.06493 (2021)](https://arxiv.org/abs/2004.06493)\n",
    "\n",
    "<img alt=\"rnn_sampling\" src=\"https://github.com/ADicksonLab/ml4md-jb/raw/main/Week-03/rnn_md_jadhao.png\" width=\"800px\"/>\n",
    "\n",
    "Recurrent neural networks are well-suited for generating iterative trajectory sampling as in molecular dynamics or Monte Carlo simulations but with longer time steps.\n",
    "\n",
    "See also [recent work from the Tiwary lab](https://www.nature.com/articles/s41467-020-18959-8)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae84271",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transformers\n",
    "\n",
    "<img alt=\"transformers\" src=\"https://github.com/ADicksonLab/ml4md-jb/raw/main/Week-03/transformer.png\" width=\"300px\"/>\n",
    "\n",
    "Transfomers are more flexible architectures that are replacing RNNs.  All of the elements may be a combination of deep (convolutional) network layers.\n",
    "\n",
    "For structure prediction the 'input' may be multiple sequence alignments and the 'target' may be an initial template-based model that is subsequently refined via multiple rounds through the decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e38151",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Attention\n",
    "\n",
    "<img alt=\"attention\" src=\"https://github.com/ADicksonLab/ml4md-jb/raw/main/Week-03/attention.png\" width=\"400px\"/>\n",
    "\n",
    "Transfomers often incorporate attention modules to capture relationships between different elements of sequential data (such as language, sequence data, spatial proximity)."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
