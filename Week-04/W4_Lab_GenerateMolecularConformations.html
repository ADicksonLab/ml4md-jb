
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Week 04 Lab: Generating Molecular Conformations &#8212; Machine Learning for Molecular Dynamics</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../_static/ml4md_fav.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Week 05 Lecture: Protein Structure Prediction in the Age of Artificial Intelligence" href="../Week-05/W5_Lecture-ProteinStructurePrediction.html" />
    <link rel="prev" title="Week 04 Lecture: Generating things with ML" href="W4_Lecture_GenerativeModels.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Machine Learning for Molecular Dynamics</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Welcome to Machine Learning for Molecular Dynamics - BMB 961 Sec 003
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Course Materials
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Course_Materials/BMB961-003_Syllabus.html">
   Syllabus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Course_Materials/BMB961-003_Schedule.html">
   Course Schedule
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Course_Materials/SoftwareSetupGuide.html">
   Software Setup Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/ADicksonLab/ml4md-jb/raw/main/Course_Materials/Final_project_description.pdf">
   Final Project Description
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Week 01
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Week-01/W1_Lecture_Welcome.html">
   Week 01 Lecture: Welcome to ML4MD
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Week-01/W1_Lab_Python_Refresher.html">
   Week 01 Lab: Python Refresher Course
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/ADicksonLab/ml4md-jb/raw/main/Course_Materials/learn_python.zip">
   LearnPython.zip
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/ADicksonLab/ml4md-jb/blob/8bc6b5d18b4f72c40ad50704cb6507c58f7f595c/Course_Materials/BMB_Community_Standards.pdf">
   BMB_Community_Standards.pdf
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://raw.githubusercontent.com/ADicksonLab/ml4md-jb/main/Week-01/sEH_nowater.pdb">
   sEH_nowater.pdb
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/ADicksonLab/ml4md-jb/raw/main/Week-01/sEH_unbinding.dcd">
   sEH_unbinding.dcd
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Week 02
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Week-02/W2_Lecture_MLBasics.html">
   Week 02 Lecture: Machine Learning at the Intersection with Molecular Simulations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Week-02/W2_Lab_MLBasics.html">
   Week 02 Lab: Machine Learning Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/ADicksonLab/ml4md-jb/raw/main/Week-02/apple.vacuum.dat">
   apple.vacuum.dat
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/ADicksonLab/ml4md-jb/raw/main/Week-02/apple.vacuum.highres.dat">
   apple.vacuum.highres.dat
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/ADicksonLab/ml4md-jb/raw/main/Week-02/apple.leaf.air.highres.dat">
   apple.leaf.air.highres.dat
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Week 03
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Week-03/W3_Lecture_NNArchitectures.html">
   Week 03 Lecture: Neural Network Architectures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Week-03/W3_Lab_ConvNetworks.html">
   Week 03 Lab: Convolutional Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/ADicksonLab/ml4md-jb/raw/main/Week-03/aq15_pdbs.tgz">
   aq15_pdbs.tgz
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/ADicksonLab/ml4md-jb/raw/main/Week-03/aq15.rgyr.dat">
   aq15.rgyr.dat
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/ADicksonLab/ml4md-jb/raw/main/Week-03/aq15.pb.dat">
   aq15.pb.dat
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/ADicksonLab/ml4md-jb/raw/main/Week-03/aq15.gb.dat">
   aq15.gb.dat
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/ADicksonLab/ml4md-jb/raw/main/Week-03/aq15.sasa.dat">
   aq15.sasa.dat
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Week 04
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="W4_Lecture_GenerativeModels.html">
   Week 04 Lecture: Generating things with ML
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Week 04 Lab: Generating Molecular Conformations
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Week 05
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Week-05/W5_Lecture-ProteinStructurePrediction.html">
   Week 05 Lecture: Protein Structure Prediction in the Age of Artificial Intelligence
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Week-05/W5_Lab_StructurePrediction.html">
   Week 05 Lab: Structure Prediction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/ADicksonLab/ml4md-jb/raw/main/Week-05/work7efy.zip">
   work7efy.zip
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Week 06
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Week-06/W6_Lecture_MD-Concepts1.html">
   Week 06 Lecture: Molecular Dynamics Concepts 1
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Week-06/W6_Lab_Single-Particle-Langevin-Dynamics.html">
   Week 06 Lab: Single Particle Langevin Dynamics
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Week 07
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Week-07/W7_Lecture_MD-Concepts2.html">
   Week 07 Lecture: Molecular Dynamics Concepts 2
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Week-07/W7_Lab_Liquid-Argon-Simulation.html">
   Week 07 Lab: Liquid Argon Simulation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/ADicksonLab/ml4md-jb/blob/main/Week-07/traj_pos_T50.npy?raw=true">
   traj_pos_T50.npy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/ADicksonLab/ml4md-jb/blob/main/Week-07/traj_vel_T50.npy?raw=true">
   traj_vel_T50.npy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/ADicksonLab/ml4md-jb/blob/main/Week-07/traj_pos_T80.npy?raw=true">
   traj_pos_T80.npy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/ADicksonLab/ml4md-jb/blob/main/Week-07/traj_pos_T120.npy?raw=true">
   traj_pos_T120.npy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/ADicksonLab/ml4md-jb/blob/main/Week-07/traj_pos_T200.npy?raw=true">
   traj_pos_T200.npy
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Week 08
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Week-08/W8_Lecture-Biomolecular-Simulation-1.html">
   Week 8 Lecture: Biomolecular Simulation (Part I)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://raw.githubusercontent.com/ADicksonLab/ml4md-jb/main/Week-08/input.pdb">
   input.pdb
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://raw.githubusercontent.com/ADicksonLab/ml4md-jb/main/Week-08/water.pdb">
   water.pdb
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Week-08/W8_Lab-Angiotensin-Simulation.html">
   Biomolecular Simulation (Lab 1)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://raw.githubusercontent.com/ADicksonLab/ml4md-jb/main/Week-08/angiotensin.pdb">
   angiotensin.pdb
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Week-08/software.html">
   Commands to install openmm in Colab
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Week 09
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Week-09/W9_Lecture-MarkovStateModels.html">
   Week 09 Lecture: Biomolecular Simulation (Part II)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Week-09/W9_Lab-SimulationAnalysis.html">
   Week 09 Lab: Analysis of MD trajectories with Markov State Models
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/Week-04/W4_Lab_GenerateMolecularConformations.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/ADicksonLab/ml4md-jb"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/ADicksonLab/ml4md-jb/issues/new?title=Issue%20on%20page%20%2FWeek-04/W4_Lab_GenerateMolecularConformations.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/ADicksonLab/ml4md-jb/main?urlpath=tree/Week-04/W4_Lab_GenerateMolecularConformations.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/ADicksonLab/ml4md-jb/blob/main/Week-04/W4_Lab_GenerateMolecularConformations.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Week 04 Lab: Generating Molecular Conformations
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#student-name-your-name-here">
     Student Name: YOUR NAME HERE
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generating-molecular-conformations-with-machine-learning">
     Generating molecular conformations with machine learning
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#downloading-data">
     Downloading data
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#initialize-our-environment">
     Initialize our environment
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#prepare-data">
     Prepare data
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#load-xyz-data">
       Load xyz data
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#reshape-arrays">
       Reshape arrays
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#select-a-random-portion-of-the-whole-md-data">
       Select a random portion of the whole MD data
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#use-mdtraj-for-the-analysis-and-modification-of-our-md-data">
       Use mdtraj for the analysis and modification of our MD data
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#analyze-distance-distributions">
       Analyze distance distributions.
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#ramachandran-plot">
       Ramachandran plot
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#build-and-train-a-generative-adversarial-network-gan">
     Build and train a Generative Adversarial Network (GAN)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#dataloader">
       Dataloader
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#build-our-generator-network">
       Build our Generator network
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#build-our-discriminator-network">
       Build our Discriminator network
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optimizers-and-loss-functions">
     Optimizers and Loss Functions
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#functions-to-train-the-model">
     Functions to train the model
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluate-our-gan">
     Evaluate our GAN
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusions">
   Conclusions
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="week-04-lab-generating-molecular-conformations">
<h1>Week 04 Lab: Generating Molecular Conformations<a class="headerlink" href="#week-04-lab-generating-molecular-conformations" title="Permalink to this headline">¶</a></h1>
<div class="section" id="student-name-your-name-here">
<h2>Student Name: YOUR NAME HERE<a class="headerlink" href="#student-name-your-name-here" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="generating-molecular-conformations-with-machine-learning">
<h2>Generating molecular conformations with machine learning<a class="headerlink" href="#generating-molecular-conformations-with-machine-learning" title="Permalink to this headline">¶</a></h2>
<p>In this lab we will build a generative model (based on neural networks) that learns how to generate molecular conformations.</p>
<p>We will work with the MD simulation data for the “alanine dipeptide” molecule. This simple molecule is frequently used as a system to develop and benchmark new methods for the analysis and modeling of molecular dynamics data. An example conformation is shown below:</p>
<img alt="Alanine dipeptide" src="https://raw.githubusercontent.com/ADicksonLab/ml4md-jb/main/Week-04/alanine_dipeptide.png" width="350px"/>
<p>Note: the molecule is an alanine capped with an acetyl group at the N-terminus and N-methylamide at the C-terminus.</p>
</div>
<div class="section" id="downloading-data">
<h2>Downloading data<a class="headerlink" href="#downloading-data" title="Permalink to this headline">¶</a></h2>
<p>We will first download a set of conformations for the alanine dipeptide.</p>
<p>The data is freely available at the <a class="reference external" href="https://markovmodel.github.io/mdshare/ALA2/">mdshare repository</a> (from the  <a class="reference external" href="http://www.mi.fu-berlin.de/en/math/groups/comp-mol-bio/index.html">Computational Molecular Biology Group, Freie Universität Berlin</a>) and is licensed under <a class="reference external" href="http://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>.</p>
<p>You can download it from your browser here:</p>
<ul class="simple">
<li><p>MD data: <a class="reference external" href="http://ftp.imp.fu-berlin.de/pub/cmb-data/alanine-dipeptide-3x250ns-heavy-atom-positions.npz">alanine-dipeptide-3x250ns-heavy-atom-positions.npz</a></p></li>
<li><p>Topology file: <a class="reference external" href="http://ftp.imp.fu-berlin.de/pub/cmb-data/alanine-dipeptide-nowater.pdb">alanine-dipeptide-nowater.pdb</a></p></li>
</ul>
<p>Instead of downloading it via the browswer, you can use <code class="docutils literal notranslate"><span class="pre">wget</span></code> in the cell below. That may be convenient when using Google Colab.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># !wget -nc http://ftp.imp.fu-berlin.de/pub/cmb-data/alanine-dipeptide-nowater.pdb</span>
<span class="c1"># !wget -nc http://ftp.imp.fu-berlin.de/pub/cmb-data/alanine-dipeptide-3x250ns-heavy-atom-positions.npz</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="initialize-our-environment">
<h2>Initialize our environment<a class="headerlink" href="#initialize-our-environment" title="Permalink to this headline">¶</a></h2>
<p>Let’s import all the libraries that we will need.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.colors</span>
<span class="kn">import</span> <span class="nn">mdtraj</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">nglview</span> <span class="k">as</span> <span class="nn">nv</span>
    <span class="kn">from</span> <span class="nn">nglview</span> <span class="kn">import</span> <span class="n">NGLWidget</span>
    <span class="n">has_nglview</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Could not import nglview.&quot;</span><span class="p">)</span>
    <span class="n">has_nglview</span> <span class="o">=</span> <span class="kc">False</span>
    
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
</pre></div>
</div>
</div>
</div>
<p>Decide which device we want to run on pytorch (which we will use to implement neural networks)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Using device &#39;</span><span class="si">%s</span><span class="s2">&#39;&quot;</span> <span class="o">%</span> <span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="prepare-data">
<h2>Prepare data<a class="headerlink" href="#prepare-data" title="Permalink to this headline">¶</a></h2>
<div class="section" id="load-xyz-data">
<h3>Load xyz data<a class="headerlink" href="#load-xyz-data" title="Permalink to this headline">¶</a></h3>
<p>We will work with xyz coordinates of heavy atoms stored in the <code class="docutils literal notranslate"><span class="pre">alanine-dipeptide-3x250ns-heavy-atom-positions.npz</span></code> file.</p>
<p>This file stores x, y and z coordinates of three MD trajectories as numpy arrays of shape <code class="docutils literal notranslate"><span class="pre">(T,</span> <span class="pre">N*3)</span></code>, where <code class="docutils literal notranslate"><span class="pre">T</span></code> is the number of frames (that is, conformations), <code class="docutils literal notranslate"><span class="pre">N</span></code> is the number of atoms in the system and <code class="docutils literal notranslate"><span class="pre">3</span></code> is for the cartesian coordinates of each atom.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_filepath</span> <span class="o">=</span> <span class="s2">&quot;alanine-dipeptide-3x250ns-heavy-atom-positions.npz&quot;</span>

<span class="c1"># We want to collect our the frames in this variable.</span>
<span class="n">all_xyz</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Load the data.</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">data_filepath</span><span class="p">)</span>
<span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
    <span class="c1"># Each key is used to store an array.</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Trajectory with key </span><span class="si">%s</span><span class="s2"> has shape: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">repr</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)))</span>
    <span class="n">all_xyz</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">key</span><span class="p">])</span>
<span class="c1"># Concatenate the arrays.</span>
<span class="n">all_xyz</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">all_xyz</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- All frames are concatenated in an array with shape:&quot;</span><span class="p">,</span> <span class="n">all_xyz</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="reshape-arrays">
<h3>Reshape arrays<a class="headerlink" href="#reshape-arrays" title="Permalink to this headline">¶</a></h3>
<p>For analysis purposes, we will reshape the arrays that store our MD data.</p>
<p>We start with <code class="docutils literal notranslate"><span class="pre">(T,</span> <span class="pre">N*3)</span></code> arrays and want to reshape them to <code class="docutils literal notranslate"><span class="pre">(T,</span> <span class="pre">N,</span> <span class="pre">3)</span></code>.</p>
<p>Insert in the cell below the number of atoms that we have in our system.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_atoms</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Your code here.</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">number_of_frames</span> <span class="o">=</span> <span class="n">all_xyz</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Now reshape the array with our data. You can use the numpy <code class="docutils literal notranslate"><span class="pre">reshape</span></code> method for arrays.
See <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.reshape.html">https://numpy.org/doc/stable/reference/generated/numpy.ndarray.reshape.html</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">all_xyz</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Your code here.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Final xyz array shape:&quot;</span><span class="p">,</span> <span class="n">all_xyz</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="select-a-random-portion-of-the-whole-md-data">
<h3>Select a random portion of the whole MD data<a class="headerlink" href="#select-a-random-portion-of-the-whole-md-data" title="Permalink to this headline">¶</a></h3>
<p>We actually have a lot of MD frames for this simple system (750 ns of MD data). We can assume that the conformational space of this molecule was sampled exhaustively in these simulations.</p>
<p>For our purposes today, we will need only a small portion of these frames. Training a generative model with all of the data could take too much time.</p>
<p>Let’s randomly select only a certain random of frames, these are the ones that we will use!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">number_of_random_frames</span> <span class="o">=</span> <span class="mi">50000</span>  <span class="c1"># You can increase or decrease this number to see how</span>
                                 <span class="c1"># it will affect our generative modeling study.</span>
</pre></div>
</div>
</div>
</div>
<p>First select some random ids. We first the <code class="docutils literal notranslate"><span class="pre">numpy.random.choice</span></code> function (<a class="reference external" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html">https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html</a>) to generate some random ids. Then we select from our original array the frames corresponding to those ids.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">random_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">all_xyz</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">number_of_random_frames</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">all_xyz</span> <span class="o">=</span> <span class="n">all_xyz</span><span class="p">[</span><span class="n">random_ids</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Now our MD data has shape:&quot;</span><span class="p">,</span> <span class="n">all_xyz</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="use-mdtraj-for-the-analysis-and-modification-of-our-md-data">
<h3>Use mdtraj for the analysis and modification of our MD data<a class="headerlink" href="#use-mdtraj-for-the-analysis-and-modification-of-our-md-data" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">mdtraj</span></code> has a lot of extremely useful functionalities, we will use some of them.</p>
<p>First of all, we will initialize a <code class="docutils literal notranslate"><span class="pre">Topology</span></code> object for the heavy-atom representation of our molecule. The details in this cell are not important for today’s lecture, so feel free to just run the code.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">topology_filepath</span> <span class="o">=</span> <span class="s2">&quot;alanine-dipeptide-nowater.pdb&quot;</span>
<span class="n">allatom_topology</span> <span class="o">=</span> <span class="n">mdtraj</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">topology_filepath</span><span class="p">)</span><span class="o">.</span><span class="n">topology</span>
<span class="n">heavyatom_topology</span> <span class="o">=</span> <span class="n">allatom_topology</span><span class="o">.</span><span class="n">subset</span><span class="p">(</span><span class="n">allatom_topology</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;element != H&quot;</span><span class="p">))</span>
<span class="n">heavyatom_topology</span>
</pre></div>
</div>
</div>
</div>
<p>Then we will create a <code class="docutils literal notranslate"><span class="pre">Trajectory</span></code> object for our MD data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m_traj</span> <span class="o">=</span> <span class="n">mdtraj</span><span class="o">.</span><span class="n">Trajectory</span><span class="p">(</span><span class="n">xyz</span><span class="o">=</span><span class="n">all_xyz</span><span class="p">,</span>
                           <span class="n">topology</span><span class="o">=</span><span class="n">heavyatom_topology</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s take a look at the conformations in our MD data by using <code class="docutils literal notranslate"><span class="pre">nglview</span></code> (if installed).</p>
<p>Please note that we randomly selected our MD frames, so the frames in the trajectory will not be in “chronological” order.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">has_nglview</span><span class="p">:</span>
    <span class="n">m_view</span> <span class="o">=</span> <span class="n">nv</span><span class="o">.</span><span class="n">show_mdtraj</span><span class="p">(</span><span class="n">m_traj</span><span class="p">)</span>
    <span class="n">m_view</span><span class="o">.</span><span class="n">center</span><span class="p">()</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">m_view</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">m_view</span>
</pre></div>
</div>
</div>
</div>
<p>The conformations seem to be somewhat centered. That’s lucky! Our generative model will generate xyz coordinates. We will use neural networks that are NOT SE(3) invariant. This means that rotating or translating the conformations could drastically alter the way our networks see the conformations.</p>
<p>Since our conformations are centered, we will not need to alter their coordinates. In general, you might want to center your data on some reference conformation if you want to train a machine learning model.</p>
<p>We will discuss experiments to see what happens to our generative model if the conformations are not centered.</p>
<p>The best way to represent 3D conformation in machine learning is still an open problem.</p>
</div>
<div class="section" id="analyze-distance-distributions">
<h3>Analyze distance distributions.<a class="headerlink" href="#analyze-distance-distributions" title="Permalink to this headline">¶</a></h3>
<p>In order to check if our generative model is doing a good job at approximating the distribution of conformations in our MD data, we will consider interatomic distances. Right now, we only have xyz coordinates for our MD data, so we will need to compute the corresponding distance matrix data.</p>
<p>First, let’s print the atoms names and their indices. This will be useful when we will start looking at interatomic distance distributions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Atom indices&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">atom_i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">m_traj</span><span class="o">.</span><span class="n">topology</span><span class="o">.</span><span class="n">atoms</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">atom_i</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Here we will compute the distance map. We define a function that we will also use later.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">convert_xyz_to_dmap</span><span class="p">(</span><span class="n">xyz</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Gets as input a xyz array of shape (T, N, 3), where T is the number of frames and</span>
<span class="sd">    N is the number of atoms.</span>
<span class="sd">    Computes the distance matrix for each conformation and returns an new array of</span>
<span class="sd">    shape (T, N, N).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">xyz</span><span class="p">[:,</span><span class="kc">None</span><span class="p">,:,:]</span> <span class="o">-</span> <span class="n">xyz</span><span class="p">[:,:,</span><span class="kc">None</span><span class="p">,:]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-12</span><span class="p">)</span>

<span class="n">all_dmap</span> <span class="o">=</span> <span class="n">convert_xyz_to_dmap</span><span class="p">(</span><span class="n">all_xyz</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Shape of distance matrix trajectory:&quot;</span><span class="p">,</span> <span class="n">all_dmap</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s plot some random distance matrices from our data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">all_dmap</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">10</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Frame&quot;</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">all_dmap</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s plot the distance distributions of all the inter-atomic distances in our molecule.</p>
<p>Note: if our molecule has <code class="docutils literal notranslate"><span class="pre">N</span></code> atoms, we will have a total of <code class="docutils literal notranslate"><span class="pre">(Nx(N-1))/2</span></code> inter-atomic distances.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_atoms</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_atoms</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">j</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Distance between atoms </span><span class="si">%s</span><span class="s2"> and </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">all_dmap</span><span class="p">[:,</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">],</span> <span class="n">histtype</span><span class="o">=</span><span class="s2">&quot;step&quot;</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;nm&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Density&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>How do the distributions look like? Are there some multi-modal distributions? If you find some some multi-modal distributions, why do you think they are in our MD data for this molecule? And also, how come some distribution are mono-modal and some multi-modal? Please take a moment to briefly discuss!</p>
</div>
<div class="section" id="ramachandran-plot">
<h3>Ramachandran plot<a class="headerlink" href="#ramachandran-plot" title="Permalink to this headline">¶</a></h3>
<p>To better understand our data, we will also plot it’s Ramachandran plot with a function that uses <code class="docutils literal notranslate"><span class="pre">mdtraj</span></code> and <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">show_ramachandran_plot</span><span class="p">(</span><span class="n">m_traj</span><span class="p">):</span>
    <span class="n">all_phi</span> <span class="o">=</span> <span class="n">mdtraj</span><span class="o">.</span><span class="n">compute_phi</span><span class="p">(</span><span class="n">m_traj</span><span class="p">)[</span><span class="mi">1</span><span class="p">][:,</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">all_psi</span> <span class="o">=</span> <span class="n">mdtraj</span><span class="o">.</span><span class="n">compute_psi</span><span class="p">(</span><span class="n">m_traj</span><span class="p">)[</span><span class="mi">1</span><span class="p">][:,</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">hist2d</span><span class="p">(</span><span class="n">all_phi</span><span class="p">,</span> <span class="n">all_psi</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">nipy_spectral_r</span><span class="p">,</span>
               <span class="n">norm</span><span class="o">=</span><span class="n">matplotlib</span><span class="o">.</span><span class="n">colors</span><span class="o">.</span><span class="n">LogNorm</span><span class="p">())</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$p_</span><span class="si">{data}</span><span class="s2">$&quot;</span><span class="p">)</span>
    <span class="c1"># plt.title(r&quot;$\mu$&quot;)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\phi$&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\psi$&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">show_ramachandran_plot</span><span class="p">(</span><span class="n">m_traj</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Do you notice something that can backup your hypotheses on the presence of multi-modal distributions in our MD data?</p>
</div>
</div>
<div class="section" id="build-and-train-a-generative-adversarial-network-gan">
<h2>Build and train a Generative Adversarial Network (GAN)<a class="headerlink" href="#build-and-train-a-generative-adversarial-network-gan" title="Permalink to this headline">¶</a></h2>
<p>Finally, after inspecting our data, we are ready to build a generative model to model it!</p>
<p>In this lab, we will use a <a class="reference external" href="https://arxiv.org/abs/1701.00160">Generative Adverarial Network</a> (GAN). We covered some theoretical details in the <a class="reference external" href="https://adicksonlab.github.io/ml4md-jb/Week-04/W4_Lecture_GenerativeModels.html">past lecture</a>, but in this notebook we will review again the main concepts of the method.</p>
<p>We will use the <code class="docutils literal notranslate"><span class="pre">pytorch</span></code> framework to implement our generative model. To review the basic functionalities of PyTorch, please refer to this <a class="reference external" href="https://pytorch.org/tutorials/beginner/basics/intro.html">tutorial</a>.</p>
<p>The GAN implementation that we will use is largely based on this <a class="reference external" href="https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html">GAN tutorial</a> on the Pytorch website.</p>
<p>Feel free to check these tutorials if you want to review and better understand the details of today’s lab.</p>
<div class="section" id="dataloader">
<h3>Dataloader<a class="headerlink" href="#dataloader" title="Permalink to this headline">¶</a></h3>
<p>A PyTorch <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> object will be necessary to split our training set in random batches and store our data in <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> objects, which are the PyTorch equivalent for NumPy arrays.</p>
<p>Note that the size of our batches is an important hyper-parameter of our neural network training, which you might need to fine-tune empirically. See this <a class="reference external" href="https://machinelearningmastery.com/how-to-control-the-speed-and-stability-of-training-neural-networks-with-gradient-descent-batch-size/">blog post</a> for an introductory discussion if you are interested.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>  <span class="c1"># This batch size value is probably good for today&#39;s learning task.</span>
                  <span class="c1"># Feel free to experiment with other values!</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">all_xyz</span><span class="p">,</span>
                                         <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">total_frames</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
    <span class="n">total_frames</span> <span class="o">+=</span> <span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Current batch shape: </span><span class="si">%s</span><span class="s2">, total frames so far: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span>
          <span class="nb">repr</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="n">total_frames</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="build-our-generator-network">
<h3>Build our Generator network<a class="headerlink" href="#build-our-generator-network" title="Permalink to this headline">¶</a></h3>
<p>Time to build our Generator network. We will use a simple <a class="reference external" href="https://en.wikipedia.org/wiki/Multilayer_perceptron">multilayer perceptron</a> (MLP) architecture, which should be more than enough to model our small molecule. Check also its image from <a class="reference external" href="https://adicksonlab.github.io/ml4md-jb/Week-02/W2_Lecture_MLBasics.html#neural-networks">Week 2 lecture</a>.</p>
<p>The generator is a network that takes as input a random noise vector <code class="docutils literal notranslate"><span class="pre">z</span></code> and maps it to some other vector <code class="docutils literal notranslate"><span class="pre">x</span></code> using some complicated function (we use a MLP). We want to train our generator to learn a function that maps <code class="docutils literal notranslate"><span class="pre">z</span></code> to <code class="docutils literal notranslate"><span class="pre">x</span></code> values that represent “realistic” 3D conformations.</p>
<p>We will use <code class="docutils literal notranslate"><span class="pre">16</span></code> as the dimension of our latent space from where the <code class="docutils literal notranslate"><span class="pre">z</span></code> vectors are sampled. Again, this is some hyper-parameter that would need fine-tuning, but <code class="docutils literal notranslate"><span class="pre">16</span></code> is probably a good value here. Usually, the dimension of <code class="docutils literal notranslate"><span class="pre">z</span></code> is supposed to be lower than that <code class="docutils literal notranslate"><span class="pre">x</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_z</span> <span class="o">=</span> <span class="mi">16</span>  <span class="c1"># Latent space dimension.</span>
<span class="n">hidden_dim_g</span> <span class="o">=</span> <span class="mi">196</span>  <span class="c1"># Number of hidden units in our generator MLP.</span>
                    <span class="c1"># In GANs, the competing generator and discriminator should be &quot;balanced&quot;</span>
                    <span class="c1"># so we will need to use a similar value for the discriminator (see below).</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Generator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_z</span><span class="p">,</span> <span class="n">n_atoms</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                 <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span>
                 <span class="n">layer_norm</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Define our neural network layers.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Generator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_atoms</span> <span class="o">=</span> <span class="n">n_atoms</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_z</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">act_0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">act_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">n_atoms</span><span class="o">*</span><span class="mi">3</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function is called when we run an instance of our</span>
<span class="sd">        neural network.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_0</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_1</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_1</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">x_gen</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="c1"># We reshape to a xyz tensor in the mdtraj (T, N, 3) style.</span>
        <span class="n">x_gen</span> <span class="o">=</span> <span class="n">x_gen</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_atoms</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x_gen</span>

<span class="n">net_g</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">(</span><span class="n">n_z</span><span class="o">=</span><span class="n">n_z</span><span class="p">,</span> <span class="n">n_atoms</span><span class="o">=</span><span class="n">n_atoms</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="n">hidden_dim_g</span><span class="p">)</span>
<span class="n">net_g</span> <span class="o">=</span> <span class="n">net_g</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">net_g</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s check what the generator is doing. Above you should see a scheme of its architecture.</p>
<p>Why is <code class="docutils literal notranslate"><span class="pre">16</span></code> the dimension of its input vectors? Why is <code class="docutils literal notranslate"><span class="pre">30</span></code> the dimension of its output vectors? What do these <code class="docutils literal notranslate"><span class="pre">30</span></code> numbers represent?</p>
<p>The cell below will allow you to run our (untrained) generator. What is its output?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="c1"># Let&#39;s generate a batch of 32 random noise vectors.</span>
    <span class="n">z_check</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">n_z</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- z shape:&quot;</span><span class="p">,</span> <span class="n">z_check</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="c1"># Let&#39;s run the generator.</span>
    <span class="n">x_check</span> <span class="o">=</span> <span class="n">net_g</span><span class="p">(</span><span class="n">z_check</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- x_gen shape:&quot;</span><span class="p">,</span> <span class="n">x_check</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="build-our-discriminator-network">
<h3>Build our Discriminator network<a class="headerlink" href="#build-our-discriminator-network" title="Permalink to this headline">¶</a></h3>
<p>Finally, let’s build our Discriminator network. We will again use a simple <a class="reference external" href="https://en.wikipedia.org/wiki/Multilayer_perceptron">multilayer perceptron</a> (MLP) architecture.</p>
<p>The discriminator is a network that takes as input a vector <code class="docutils literal notranslate"><span class="pre">x</span></code> and maps it to a scalar value in the <code class="docutils literal notranslate"><span class="pre">0-1</span></code> interval using some complicated function (we use a MLP).</p>
<p>In GAN training, we want to train our discriminator in a <a class="reference external" href="https://en.wikipedia.org/wiki/Binary_classification">binary classification</a> task, where our two classes are “fake conformation” (represented by a <code class="docutils literal notranslate"><span class="pre">0</span></code>) and “real conformantion” (represented by a <code class="docutils literal notranslate"><span class="pre">1</span></code>).</p>
<p>In GAN training, “fake” means a <code class="docutils literal notranslate"><span class="pre">x</span></code> comining from the generator, while “real” means a <code class="docutils literal notranslate"><span class="pre">x</span></code> coming from the training data.</p>
<p>In other words, when we feed to the discriminator a “fake” <code class="docutils literal notranslate"><span class="pre">x</span></code>, we would like it to output a number close to <code class="docutils literal notranslate"><span class="pre">0</span></code>, when we feed it a “real” <code class="docutils literal notranslate"><span class="pre">x</span></code>, we would like a output close to <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p>
<p><strong>Optional</strong>. Two last notes about the discriminator.</p>
<ul class="simple">
<li><p>GAN training is typically instable. There are many techniques that attempt to stabilize it. Today we will use <a class="reference external" href="https://arxiv.org/abs/1802.05957">spectral normalization</a> on the discriminator weights. It is a computationally light method and it is already implemented as a PyTorch functionality. Its effect is to regularize the discriminator by forcing it to learn a “smoother” function, something that appears to stabilize GAN training.</p></li>
<li><p>To numerically help neural network training, we also use a <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html">Standard Scaler</a> to standardize each atom coordinate using its mean and standard deviation values from the training set. A similar (but more complex) approach is followed for example in [<a class="reference external" href="https://pubmed.ncbi.nlm.nih.gov/31488660/">Noe et al., 2019</a>].</p></li>
</ul>
<p>If you want to check what happens without these features, feel free to set our <code class="docutils literal notranslate"><span class="pre">use_spectral_norm</span></code> or <code class="docutils literal notranslate"><span class="pre">use_scaler</span></code> variables to <code class="docutils literal notranslate"><span class="pre">False</span></code>!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hidden_dim_d</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">use_spectral_norm</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">use_scaler</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">StandardScaler</span><span class="p">:</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">s</span> <span class="o">=</span> <span class="kc">None</span>
        
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xyz</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">xyz</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_atoms</span><span class="o">*</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">s</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">xyz</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_atoms</span><span class="o">*</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xyz</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="o">-</span><span class="n">xyz</span><span class="p">)</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">s</span>
    
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">all_xyz</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Discriminator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_atoms</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                 <span class="n">use_scaler</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">use_spectral_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        
        <span class="nb">super</span><span class="p">(</span><span class="n">Discriminator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_atoms</span> <span class="o">=</span> <span class="n">n_atoms</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_scaler</span> <span class="o">=</span> <span class="n">use_scaler</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_spectral_norm</span> <span class="o">=</span> <span class="n">use_spectral_norm</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_atoms</span><span class="o">*</span><span class="mi">3</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_spectral_norm</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">spectral_norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">act_0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_spectral_norm</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">spectral_norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">act_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_spectral_norm</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">spectral_norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">act_sigmoid</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_atoms</span><span class="o">*</span><span class="mi">3</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_scaler</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_0</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_1</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_1</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">o</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">o</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_sigmoid</span><span class="p">(</span><span class="n">o</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">o</span>

<span class="n">net_d</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">(</span><span class="n">n_atoms</span><span class="o">=</span><span class="n">n_atoms</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="n">hidden_dim_d</span><span class="p">,</span>
                      <span class="n">use_spectral_norm</span><span class="o">=</span><span class="n">use_spectral_norm</span><span class="p">,</span>
                      <span class="n">use_scaler</span><span class="o">=</span><span class="n">use_scaler</span><span class="p">)</span>
<span class="n">net_d</span> <span class="o">=</span> <span class="n">net_d</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">net_d</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s check what the discriminator is doing. Above you should see a scheme of its architecture.</p>
<p>Why is <code class="docutils literal notranslate"><span class="pre">30</span></code> the dimension of its input vectors? Why is <code class="docutils literal notranslate"><span class="pre">1</span></code> the dimension of its output?</p>
<p>The cell below will allow you to run our (untrained) discriminator. What is its output? Notice how its output is a number between 0 and 1 (an untrained discriminator should output some random number close to <code class="docutils literal notranslate"><span class="pre">0.5</span></code>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="c1"># We extract a batch of training data.</span>
    <span class="n">x_check</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">dataloader</span><span class="o">.</span><span class="fm">__iter__</span><span class="p">())</span>
    <span class="n">x_check</span> <span class="o">=</span> <span class="n">x_check</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- x_ref shape:&quot;</span><span class="p">,</span> <span class="n">x_check</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="c1"># We give it as input to the discriminator.</span>
    <span class="n">out_check</span> <span class="o">=</span> <span class="n">net_d</span><span class="p">(</span><span class="n">x_check</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- discriminator output shape:&quot;</span><span class="p">,</span> <span class="n">out_check</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- First 10 elements of the output:&quot;</span><span class="p">,</span> <span class="n">out_check</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="optimizers-and-loss-functions">
<h2>Optimizers and Loss Functions<a class="headerlink" href="#optimizers-and-loss-functions" title="Permalink to this headline">¶</a></h2>
<p>We are almost ready to train our GAN! Let’s create our <code class="docutils literal notranslate"><span class="pre">Adam</span></code> optimizers to perform gradient-based optimization of neural network parameters. <a class="reference external" href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Adam">Adam</a> is a more sophisticated version of the basic <a class="reference external" href="https://en.wikipedia.org/wiki/Gradient_descent">Steepest Descent</a> algorithm (which you may know from Molecular Mechanics), it is the default choice of almost all machine learning practitioners.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Establish convention for real and fake labels during training</span>
<span class="n">real_label</span> <span class="o">=</span> <span class="mf">1.</span>
<span class="n">fake_label</span> <span class="o">=</span> <span class="mf">0.</span>

<span class="c1"># Setup Adam optimizers for both G and D</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.00025</span>
<span class="n">beta1</span> <span class="o">=</span> <span class="mf">0.25</span>
<span class="n">optimizer_d</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">net_d</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="n">beta1</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">))</span>
<span class="n">optimizer_g</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">net_g</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="n">beta1</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Here we create our loss function. Today, we will use a slightly modified version of the <span class="xref myst">original GAN objective</span>.</p>
<p>This modification is called the non-saturated GAN loss and was discussed in the original <a class="reference external" href="https://arxiv.org/abs/1406.2661">GAN article</a> as a form of improvement over the original minmax objective.</p>
<p>Here is its formula (image from [<a class="reference external" href="https://arxiv.org/abs/2003.06060">Che et al., 2020</a>]):</p>
<img alt="non-saturated GAN loss" src="https://raw.githubusercontent.com/ADicksonLab/ml4md-jb/main/Week-04/non_saturated_gan_loss.png" width="500px"/>
<p>Where:</p>
<ul class="simple">
<li><p><em>L<sub>D</sub></em> is the discriminator loss and <em>L<sub>G</sub></em> is the generator loss.</p></li>
<li><p><em>D(<strong>x</strong>)</em> is the discriminator output (a scalar from 0 to 1).</p></li>
<li><p><em>G(<strong>z</strong>)</em> is the generator output, a “fake” conformation <em><strong>x</strong></em>.</p></li>
<li><p>The <a class="reference external" href="https://en.wikipedia.org/wiki/Expected_value">Expected_value</a> is computed over:</p>
<ul>
<li><p><em>p<sub>data</sub></em> (something that we approximate by sampling batches of conformation from our training set)</p></li>
<li><p><em>p<sub>z</sub></em> (something that we approximate by generating random samples by sampling from our simple prior).</p></li>
</ul>
</li>
</ul>
<p>In our GAN implemenentation, for each mini-batch will first train the discriminator by using <em>L<sub>D</sub></em>, and then the generator using <em>L<sub>G</sub></em>.</p>
<p>What is the goal of training with these functions?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialize BCELoss function, which we will use to compute L_D and L_G.</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Create batch of latent vectors that we will use to visualize the progression of the generator.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">z_fixed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="n">n_z</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="functions-to-train-the-model">
<h2>Functions to train the model<a class="headerlink" href="#functions-to-train-the-model" title="Permalink to this headline">¶</a></h2>
<p>Now we are ready to train! In the cell below there is function that implement GAN training for <code class="docutils literal notranslate"><span class="pre">num_epochs</span></code>. In machine learning a training epoch is a pass through all the training examples. GAN training can be quite slow sometimes, so you may need to train at least 50 epochs to see some acceptable results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">score_kl_approximation</span><span class="p">(</span><span class="n">v_true</span><span class="p">,</span> <span class="n">v_pred</span><span class="p">,</span> <span class="n">n_bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">pseudo_c</span><span class="o">=</span><span class="mf">0.00001</span><span class="p">):</span>
    <span class="c1"># Define bins.</span>
    <span class="n">_min</span> <span class="o">=</span> <span class="nb">min</span><span class="p">((</span><span class="n">v_true</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">v_pred</span><span class="o">.</span><span class="n">min</span><span class="p">()))</span>
    <span class="n">_max</span> <span class="o">=</span> <span class="nb">max</span><span class="p">((</span><span class="n">v_true</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">v_pred</span><span class="o">.</span><span class="n">max</span><span class="p">()))</span>
    <span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">_min</span><span class="p">,</span> <span class="n">_max</span><span class="p">,</span> <span class="n">n_bins</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># Compute the frequencies in the bins.</span>
    <span class="n">ht</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">v_true</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">pseudo_c</span><span class="p">)</span><span class="o">/</span><span class="n">v_true</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">hp</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">v_pred</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">pseudo_c</span><span class="p">)</span><span class="o">/</span><span class="n">v_pred</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">kl</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ht</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">hp</span><span class="o">/</span><span class="n">ht</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">kl</span><span class="p">,</span> <span class="n">bins</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>

    <span class="c1"># Lists to keep track of progress.</span>
    <span class="n">history</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Starting Training Loop...</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># For each epoch</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"># Epoch </span><span class="si">%s</span><span class="s2"> of </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">))</span>
        
        <span class="c1"># We set to training mode our networks.</span>
        <span class="n">net_d</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">net_g</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="n">epoch_data</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;loss_d&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;loss_g&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                      <span class="s2">&quot;D_x&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                      <span class="s2">&quot;D_G_z1&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                      <span class="s2">&quot;D_G_z2&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                      <span class="s2">&quot;epoch_elements&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>

        <span class="c1"># For each batch in the dataloader</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x_real</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>

            <span class="c1">############################</span>
            <span class="c1"># (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))</span>
            <span class="c1">###########################</span>

            <span class="c1">## Train with all-real batch</span>

            <span class="c1"># Zero-out the gradients of netD.</span>
            <span class="n">net_d</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="c1"># Format batch</span>
            <span class="n">x_real</span> <span class="o">=</span> <span class="n">x_real</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">b_size</span> <span class="o">=</span> <span class="n">x_real</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

            <span class="c1"># Store the number of samples processed in this epoch.</span>
            <span class="n">epoch_data</span><span class="p">[</span><span class="s2">&quot;epoch_elements&quot;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">b_size</span>

            <span class="c1"># Create a tensor with shape (b_size,) with only 1 values,</span>
            <span class="c1"># since 1 is the label of real samples.</span>
            <span class="n">label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">b_size</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># Forward pass real batch through D.</span>
            <span class="c1"># We use.view(-1) to reshape from (b_size, 1) -&gt; (b_size, )</span>
            <span class="n">out_real</span> <span class="o">=</span> <span class="n">net_d</span><span class="p">(</span><span class="n">x_real</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

            <span class="c1"># Calculate loss on all-real batch.</span>
            <span class="c1"># We want to maximize log(D(x)).</span>
            <span class="n">loss_d_real</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">out_real</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>

            <span class="c1"># Calculate gradients for D in backward pass</span>
            <span class="n">loss_d_real</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

            <span class="c1"># Stores data for calculating D_x for this epoch.</span>
            <span class="n">epoch_data</span><span class="p">[</span><span class="s2">&quot;D_x&quot;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">out_real</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>


            <span class="c1">## Train with all-fake batch</span>
            <span class="c1"># Generate batch of latent vectors</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">b_size</span><span class="p">,</span> <span class="n">n_z</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># Generate fake image batch with G</span>
            <span class="n">x_fake</span> <span class="o">=</span> <span class="n">net_g</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

            <span class="c1"># Now we fill the label tensor with 0, since that is the label of fakes</span>
            <span class="c1"># samples.</span>
            <span class="n">label</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">fake_label</span><span class="p">)</span>

            <span class="c1"># Classify all fake batch with D.</span>
            <span class="c1"># Note: detach() is needed, since we want to take x_fake out of the</span>
            <span class="c1"># computational graph: we are not interested in calculating the gradient</span>
            <span class="c1"># with respect to netG parameters now (we must do it later when updating</span>
            <span class="c1"># netG). This means that we are treating x_fake as some &quot;constant&quot; input</span>
            <span class="c1"># for the netD (just like x_true).</span>
            <span class="n">out_fake</span> <span class="o">=</span> <span class="n">net_d</span><span class="p">(</span><span class="n">x_fake</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

            <span class="c1"># Calculate D&#39;s loss on the all-fake batch.</span>
            <span class="c1"># We want to minimize log(1 - D(G(z)).</span>
            <span class="n">loss_d_fake</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">out_fake</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>

            <span class="c1"># Calculate the gradients for this batch, accumulated (summed) with previous gradients</span>
            <span class="n">loss_d_fake</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

            <span class="c1"># Compute the accuracy of netD predictions.</span>
            <span class="n">epoch_data</span><span class="p">[</span><span class="s2">&quot;D_G_z1&quot;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">out_fake</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

            <span class="c1"># Compute error of D as sum over the fake and the real batches</span>
            <span class="n">loss_d</span> <span class="o">=</span> <span class="n">loss_d_fake</span> <span class="o">+</span> <span class="n">loss_d_fake</span>

            <span class="c1"># Store the loss_d values.</span>
            <span class="n">epoch_data</span><span class="p">[</span><span class="s2">&quot;loss_d&quot;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">loss_d</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="o">*</span><span class="n">b_size</span>

            <span class="c1"># Update D</span>
            <span class="n">optimizer_d</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>


            <span class="c1">############################</span>
            <span class="c1"># (2) Update G network: maximize log(D(G(z)))</span>
            <span class="c1">###########################</span>

            <span class="c1"># Zero-out netG gradients.</span>
            <span class="n">net_g</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="n">label</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">real_label</span><span class="p">)</span>  <span class="c1"># fake labels are real for generator cost</span>

            <span class="c1"># Since we just updated D, perform another forward pass of all-fake batch through D</span>
            <span class="n">out_fake</span> <span class="o">=</span> <span class="n">net_d</span><span class="p">(</span><span class="n">x_fake</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

            <span class="c1"># Calculate G&#39;s loss based on this output.</span>
            <span class="c1"># We want to maximize log(D(G(z))).</span>
            <span class="n">loss_g</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">out_fake</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>

            <span class="c1"># Store the loss_g values.</span>
            <span class="n">epoch_data</span><span class="p">[</span><span class="s2">&quot;loss_g&quot;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">loss_g</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="o">*</span><span class="n">b_size</span>

            <span class="c1"># Calculate gradients for G</span>
            <span class="n">loss_g</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

            <span class="c1"># Calculate the accuracy for D after it was updated.</span>
            <span class="n">epoch_data</span><span class="p">[</span><span class="s2">&quot;D_G_z2&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">out_fake</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

            <span class="c1"># Update G</span>
            <span class="n">optimizer_g</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        
        <span class="c1"># We set to eval mode our networks.</span>
        <span class="n">net_d</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">net_g</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        
        <span class="c1"># Generate random conformations to check how training is going.</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">x_gen_fixed</span> <span class="o">=</span> <span class="n">net_g</span><span class="p">(</span><span class="n">z_fixed</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">dmap_gen_fixed</span> <span class="o">=</span> <span class="n">convert_xyz_to_dmap</span><span class="p">(</span><span class="n">x_gen_fixed</span><span class="p">)</span>
        
        <span class="c1"># Evaluate all the inter-atomic distance distributions.</span>
        <span class="n">kl_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_atoms</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_atoms</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">j</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="n">dist_ref</span> <span class="o">=</span> <span class="n">all_dmap</span><span class="p">[:,</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
                <span class="n">dist_gen</span> <span class="o">=</span> <span class="n">dmap_gen_fixed</span><span class="p">[:,</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
                <span class="n">kl_i</span> <span class="o">=</span> <span class="n">score_kl_approximation</span><span class="p">(</span><span class="n">dist_ref</span><span class="p">,</span> <span class="n">dist_gen</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">kl_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">kl_i</span><span class="p">)</span>
                
        <span class="c1"># Updates the history (divide each value by the number of elements</span>
        <span class="c1"># processed in this epoch, so that we have average values for the epoch.</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">epoch_data</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
            <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="s2">&quot;epoch_elements&quot;</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">epoch_data</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">epoch_data</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">/</span><span class="n">epoch_data</span><span class="p">[</span><span class="s2">&quot;epoch_elements&quot;</span><span class="p">]</span>
        <span class="n">epoch_data</span><span class="p">[</span><span class="s2">&quot;average_kld&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">kl_list</span><span class="p">)</span>
        <span class="n">history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch_data</span><span class="p">)</span>
        
        <span class="c1"># Output training process stats.</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[</span><span class="si">%d</span><span class="s1">/</span><span class="si">%d</span><span class="s1">]</span><span class="se">\t</span><span class="s1">Loss_D: </span><span class="si">%.4f</span><span class="se">\t</span><span class="s1">Loss_G: </span><span class="si">%.4f</span><span class="se">\t</span><span class="s1">D(x): </span><span class="si">%.4f</span><span class="se">\t</span><span class="s1">D(G(z)): </span><span class="si">%.4f</span><span class="s1">&#39;</span>
              <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span>
                 <span class="n">epoch_data</span><span class="p">[</span><span class="s2">&quot;loss_d&quot;</span><span class="p">],</span> <span class="n">epoch_data</span><span class="p">[</span><span class="s2">&quot;loss_g&quot;</span><span class="p">],</span>
                 <span class="n">epoch_data</span><span class="p">[</span><span class="s2">&quot;D_x&quot;</span><span class="p">],</span> <span class="n">epoch_data</span><span class="p">[</span><span class="s2">&quot;D_G_z1&quot;</span><span class="p">]))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">Average KLD for all inter-atomic distances: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">kl_list</span><span class="p">),</span> <span class="mi">4</span><span class="p">))</span>

        <span class="c1"># Plot some distance distributions.</span>
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">n_hist</span> <span class="o">=</span> <span class="mi">4</span>
            <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_hist</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">))</span>
            <span class="n">h_args</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;histtype&quot;</span><span class="p">:</span> <span class="s2">&quot;step&quot;</span><span class="p">,</span> <span class="s2">&quot;density&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;bins&quot;</span><span class="p">:</span> <span class="mi">50</span><span class="p">}</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_hist</span><span class="p">):</span>
                <span class="n">atm_i</span><span class="p">,</span> <span class="n">atm_j</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">n_atoms</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="n">dist_ref</span> <span class="o">=</span> <span class="n">all_dmap</span><span class="p">[:,</span><span class="n">atm_i</span><span class="p">,</span> <span class="n">atm_j</span><span class="p">]</span>
                <span class="n">dist_gen</span> <span class="o">=</span> <span class="n">dmap_gen_fixed</span><span class="p">[:,</span><span class="n">atm_i</span><span class="p">,</span> <span class="n">atm_j</span><span class="p">]</span>
                <span class="n">kl_i</span> <span class="o">=</span> <span class="n">score_kl_approximation</span><span class="p">(</span><span class="n">dist_ref</span><span class="p">,</span> <span class="n">dist_gen</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">ax</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Distance </span><span class="si">%s</span><span class="s2">-</span><span class="si">%s</span><span class="s2"> (KL = </span><span class="si">%s</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">atm_i</span><span class="p">,</span> <span class="n">atm_j</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">kl_i</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
                <span class="n">ax</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">dist_ref</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;MD&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">h_args</span><span class="p">)</span>
                <span class="n">ax</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">dist_gen</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;GEN&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">h_args</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
            
    <span class="k">return</span> <span class="n">history</span>
</pre></div>
</div>
</div>
</div>
<p>Here you can run the training. Start with 50 epochs. If you feel that the results are not yet acceptable, run again this cell to train for more epochs (you can also modify the number of epochs).</p>
<p>During training, we will evaluate the divergence between the reference (from MD) and generated (from our GAN) distance distributions using an approximation of the <a class="reference external" href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">Kullback–Leibler divergence</a>. The lower this score is, the more the two distribution are similar (if distributions are equal, KLD would be 0).</p>
<p>Check your average KLD! If, after some epochs it is not improving, there is probably no point in training longer.</p>
<p>To visually check how well our generator is modeling the distance distributions, we also plot some histograms every 5 epochs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="evaluate-our-gan">
<h2>Evaluate our GAN<a class="headerlink" href="#evaluate-our-gan" title="Permalink to this headline">¶</a></h2>
<p>When you are done with training it’s time to evaluate our GAN and take a look at some of the generated conformations.</p>
<p>First let’s generate the same number of conformations that we have in our training set. We will also time how much it takes for the generator to sample these conformations.</p>
<p>Note that all of these will be independent samples. It would have probably taken much longer to generate via MD the same number of statistically-independent samples!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">n_eval</span> <span class="o">=</span> <span class="n">all_xyz</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">z_eval</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_eval</span><span class="p">,</span> <span class="n">n_z</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">x_gen_eval</span> <span class="o">=</span> <span class="n">net_g</span><span class="p">(</span><span class="n">z_eval</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">dmap_gen_eval</span> <span class="o">=</span> <span class="n">convert_xyz_to_dmap</span><span class="p">(</span><span class="n">x_gen_eval</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Generated xyz array shape:&quot;</span><span class="p">,</span> <span class="n">x_gen_eval</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- It took </span><span class="si">%s</span><span class="s2"> seconds to generate </span><span class="si">%s</span><span class="s2"> independant conformations.&quot;</span> <span class="o">%</span> <span class="p">(</span>
      <span class="n">t1</span><span class="o">-</span><span class="n">t0</span><span class="p">,</span> <span class="n">x_gen_eval</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
<p>First let’s plot all the inter-atomic distance histograms. Is the GAN capturing multi-modal distributions?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_atoms</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_atoms</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">j</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">kl_i</span> <span class="o">=</span> <span class="n">score_kl_approximation</span><span class="p">(</span><span class="n">all_dmap</span><span class="p">[:,</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">],</span> <span class="n">dmap_gen_eval</span><span class="p">[:,</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Distance between atoms </span><span class="si">%s</span><span class="s2"> and </span><span class="si">%s</span><span class="s2"> (KL =  </span><span class="si">%s</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span>
                  <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">kl_i</span><span class="p">,</span> <span class="mi">4</span><span class="p">)))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">all_dmap</span><span class="p">[:,</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">],</span> <span class="n">histtype</span><span class="o">=</span><span class="s2">&quot;step&quot;</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;MD&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">dmap_gen_eval</span><span class="p">[:,</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">],</span> <span class="n">histtype</span><span class="o">=</span><span class="s2">&quot;step&quot;</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;GEN&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;nm&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Density&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>The let’s take a look at the 3D conformations using <code class="docutils literal notranslate"><span class="pre">mdtraj</span></code> and <code class="docutils literal notranslate"><span class="pre">nglview</span></code>. Do they look kind of real to you?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m_traj_gen</span> <span class="o">=</span> <span class="n">mdtraj</span><span class="o">.</span><span class="n">Trajectory</span><span class="p">(</span><span class="n">xyz</span><span class="o">=</span><span class="n">x_gen_eval</span><span class="p">,</span>
                               <span class="n">topology</span><span class="o">=</span><span class="n">heavyatom_topology</span><span class="p">)</span>

<span class="k">if</span> <span class="n">has_nglview</span><span class="p">:</span>
    <span class="n">m_view_gen</span> <span class="o">=</span> <span class="n">nv</span><span class="o">.</span><span class="n">show_mdtraj</span><span class="p">(</span><span class="n">m_traj_gen</span><span class="p">)</span>
    <span class="n">m_view_gen</span><span class="o">.</span><span class="n">center</span><span class="p">()</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">m_view_gen</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">m_view_gen</span>
</pre></div>
</div>
</div>
</div>
<p>Finally, let’s plot the Ramachandran plot for our generated ensemble. Does it bear some resemblance to the one observed in MD data? What are the most important differences? Is our GAN capturing all the metastable states in the system?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Generated Ramachandran plot&quot;</span><span class="p">)</span>
<span class="n">show_ramachandran_plot</span><span class="p">(</span><span class="n">m_traj_gen</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">- MD Ramachandran plot&quot;</span><span class="p">)</span>
<span class="n">show_ramachandran_plot</span><span class="p">(</span><span class="n">m_traj</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="conclusions">
<h1>Conclusions<a class="headerlink" href="#conclusions" title="Permalink to this headline">¶</a></h1>
<p>Congratulations! You have modeled the your first conformational ensemble of a molecule with a generative model!</p>
<p>Please take a moment to pause and discuss what are in your opinion the strenghts and weaknesses that you found for this method.</p>
<p>Unfortunately, machine learning is highly dependant on the training data. You can get a feeling of this be running again this notebook and using only a selected part of the MD data. Instead of using 50000 random conformations, we will use the first 50000 conformations in the MD data: the simulation from which this data comes from, only sampled part of the conformational ensemble of the alanine dipeptide.</p>
<p>You can select this data by restarting the notebook and substituting the line <code class="docutils literal notranslate"><span class="pre">all_xyz</span> <span class="pre">=</span> <span class="pre">all_xyz[random_ids]</span></code> with <code class="docutils literal notranslate"><span class="pre">all_xyz</span> <span class="pre">=</span> <span class="pre">all_xyz[:20000]</span></code>.</p>
<p>When you train the GAN only with this data, is it going to be able to generate conformations for all the conformational ensemble?</p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Week-04"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="W4_Lecture_GenerativeModels.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Week 04 Lecture: Generating things with ML</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../Week-05/W5_Lecture-ProteinStructurePrediction.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Week 05 Lecture: Protein Structure Prediction in the Age of Artificial Intelligence</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Alex Dickson and Michael Feig<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>